# Database Configuration
# DATABASE_URL=postgresql://docpal:docpal_dev@localhost:5432/docpal

# MinIO Configuration (S3-compatible storage)
# MINIO_ENDPOINT=localhost:9000
# MINIO_ACCESS_KEY=minioadmin
# MINIO_SECRET_KEY=minioadmin
# MINIO_USE_SSL=false

# AI/LLM Configuration (Optional)
# Configure these to enable AI-powered column type suggestions
# Leave commented out to use fallback pattern matching

# Ollama Base URL - the endpoint where your Ollama service is running
# Default: http://localhost:11434
# OLLAMA_BASE_URL=http://localhost:11434

# Ollama Model - the model to use for suggestions
# Recommended: qwen2.5-coder:7b (best for database/technical tasks)
# Alternatives: qwen2.5-coder:3b (faster), mistral (reliable), llama3.2:3b (fast)
# Default: qwen2.5-coder:7b
# OLLAMA_MODEL=qwen2.5-coder:7b

# ============================================================
# To set up AI features:
# 1. Install Ollama: https://ollama.ai/
# 2. Pull a model: ollama pull qwen2.5-coder:7b
# 3. Uncomment the OLLAMA_* variables above
# 4. Restart your dev server
# 
# Documentation:
# - Quick Start: docs/AI_QUICK_START.md
# - Full Setup: docs/AI_INTEGRATION_SETUP.md
# - Model Guide: docs/AI_MODEL_RECOMMENDATIONS.md
# ============================================================
